---
title: "MACHINE LEARNING"
author: "Datapsy1979"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r librerie}
library(tidyverse)
library(readxl)
library(writexl)
library(caret)
library(rpart)
library(rpart.plot)
library(rsample)
library(openxlsx)
library(pROC)
library(xgboost)
library(randomForest)
library(nnet)
library(readxl)
library(writexl)
library(dplyr)
```
Modelli di machine learning addestrati su dataset dataridotto
```{r}
data<-read.xlsx("dataridotto2.xlsx")
  for (col in names(data)) {
  # Controlla se la colonna è di tipo character
  if (is.character(data[[col]])) {
    # Trasforma la colonna in un fattore
    data[[col]] <- factor(data[[col]])
  }
  }


```

DECISION TREE


```{r dataset split}
set.seed(123)
data_split <- initial_split(data, prop = 0.8, strata = "gruppo")
train.data <- training(data_split)
test.data <- testing(data_split)
names(train.data)
names(test.data)
```
```{r dimensioni subset}
dim(train.data)
dim(test.data)
prop.table(table(train.data$gruppo))
prop.table(table(test.data$gruppo))
sum(!complete.cases(train.data))
sum(!complete.cases(test.data))
```
```{r}
set.seed(123)
model<-rpart( gruppo ~ ., data=train.data, method = "class")
```
```{r}
printcp(model)
summary(model)
```
```{r plot tree}
plot(model)
text(model, use.n=TRUE, all=TRUE, cex=.8)
```
```{r predictions}
predicted.classes<-model%>%
  predict(test.data, type = "class")
head(predicted.classes)

```
```{r accuracy}
mean(predicted.classes==test.data$gruppo)
```
```{r confusion matrix}
table(test.data$gruppo, predicted.classes)
confusionMatrix(predicted.classes, test.data$gruppo, positive= "1")

```
```{r pruning}
set.seed(123)
model2<-train(gruppo~., data = train.data, method= "rpart",
              trControl=trainControl("cv", number = 10),
              tuneLength=10)
plot(model2)
```
```{r}
model2$bestTune
```
```{r}
plot(model2$finalModel)
text(model2$finalModel, digits = 3)
model2$finalModel
```
```{r}
predicted.classes<-model2%>% predict(test.data)
mean(predicted.classes==test.data$gruppo)

```
Il secondo modello ottimizzato del decision tree ha perfomance peggiroi e vinee scartato.
```{r ROC}
# Calcolo ROC
roc_result <- roc(test.data$gruppo, as.numeric(predicted.classes))

# Stampa l'AUC
print(paste("AUC:", auc(roc_result)))

# Creazione del grafico ROC
plot(roc_result, main="ROC Curve", col="#1c61b6", lwd=2)
abline(a=0, b=1, lty=2, col="red")

```


```{r}


# Creare la matrice di confusione
cm <- confusionMatrix(predicted.classes, test.data$gruppo, positive = "1")

# Estrazione delle metriche dalla matrice di confusione
overall_stats <- cm$overall
cm
# statistiche generali come accuracy e Kappa
class_stats <- cm$byClass  # statistiche per classe come sensibilità, specificità, ecc.

# Creare un nuovo file Excel e un foglio per le statistiche
wb <- createWorkbook()
addWorksheet(wb, "Statistiche Complete DT")

# Preparare i dati da scrivere
metrics <- data.frame(
  Model = "Decision Tree",
    Accuracy = overall_stats["Accuracy"],
  
  Kappa = overall_stats["Kappa"],
  
  Sensitivity = class_stats["Sensitivity"],
  Specificity = class_stats["Specificity"],
  
  `Detection Rate` = class_stats["Detection Rate"],
  `Detection Prevalence` = class_stats["Detection Prevalence"],
  `Balanced Accuracy` = class_stats["Balanced Accuracy"],
  AUC= auc(roc_result)
)

# Scrivere i dati nel foglio Excel
writeDataTable(wb, "Statistiche Complete DT", metrics, withFilter = TRUE)

# Salvare il file Excel
saveWorkbook(wb, "Statistiche_Complete_DT.xlsx", overwrite = TRUE)

```

Modello SVM
```{r SVM Radial}

set.seed(123)
model <- train(
  gruppo ~., data = train.data, method = "svmRadial",
  trControl = trainControl("cv", number = 10),
  preProcess = c("center","scale"),
  tuneLength = 10
  )
# Print the best tuning parameter sigma and C that
# maximizes model accuracy
model$bestTune

```

```{r predictions e accuracy}
# Make predictions on the test data
predicted.classes <- model %>% predict(test.data)
# Compute model accuracy rate
mean(predicted.classes == test.data$gruppo)
```
```{r}
table(test.data$gruppo, predicted.classes)
confusionMatrix(predicted.classes, test.data$gruppo, positive= "1")

```
```{r ROC}
# Calcolo ROC
roc_result <- roc(test.data$gruppo, as.numeric(predicted.classes))

# Stampa l'AUC
print(paste("AUC:", auc(roc_result)))

# Creazione del grafico ROC
plot(roc_result, main="ROC Curve", col="#1c61b6", lwd=2)
abline(a=0, b=1, lty=2, col="red")

```
```{r}


# Creare la matrice di confusione
cm <- confusionMatrix(predicted.classes, test.data$gruppo, positive = "1")

# Estrazione delle metriche dalla matrice di confusione
overall_stats <- cm$overall
cm
# statistiche generali come accuracy e Kappa
class_stats <- cm$byClass  # statistiche per classe come sensibilità, specificità, ecc.

# Creare un nuovo file Excel e un foglio per le statistiche
wb <- createWorkbook()
addWorksheet(wb, "Statistiche Complete SVM")

# Preparare i dati da scrivere
metrics <- data.frame(
  Model = "SVM",
    Accuracy = overall_stats["Accuracy"],
  
  Kappa = overall_stats["Kappa"],
  
  Sensitivity = class_stats["Sensitivity"],
  Specificity = class_stats["Specificity"],
  
  `Detection Rate` = class_stats["Detection Rate"],
  `Detection Prevalence` = class_stats["Detection Prevalence"],
  `Balanced Accuracy` = class_stats["Balanced Accuracy"],
  AUC= auc(roc_result)
)

# Scrivere i dati nel foglio Excel
writeDataTable(wb, "Statistiche Complete SVM", metrics, withFilter = TRUE)

# Salvare il file Excel
saveWorkbook(wb, "Statistiche_Complete_SVM.xlsx", overwrite = TRUE)

```


Modello KNN

```{r KNN}
set.seed(123)
model <- train(
  gruppo ~., data = train.data, method = "knn",
  trControl = trainControl("cv", number = 10),
  preProcess = c("center","scale"),
  tuneLength = 20
  )
# Plot model accuracy vs different values of k
plot(model)
```
```{r miglior valore k}
model$bestTune
```
```{r predictions}
predicted.classes <- model %>% predict(test.data)
head(predicted.classes)

```
```{r confusion matrix}
table(test.data$gruppo, predicted.classes)
confusionMatrix(predicted.classes, test.data$gruppo, positive= "1")
```
```{r ROC}
# Calcolo ROC
roc_result <- roc(test.data$gruppo, as.numeric(predicted.classes))

# Stampa l'AUC
print(paste("AUC:", auc(roc_result)))

# Creazione del grafico ROC
plot(roc_result, main="ROC Curve", col="#1c61b6", lwd=2)
abline(a=0, b=1, lty=2, col="red")

```
```{r}


# Creare la matrice di confusione
cm <- confusionMatrix(predicted.classes, test.data$gruppo, positive = "1")

# Estrazione delle metriche dalla matrice di confusione
overall_stats <- cm$overall
cm
# statistiche generali come accuracy e Kappa
class_stats <- cm$byClass  # statistiche per classe come sensibilità, specificità, ecc.

# Creare un nuovo file Excel e un foglio per le statistiche
wb <- createWorkbook()
addWorksheet(wb, "Statistiche Complete KNN")

# Preparare i dati da scrivere
metrics <- data.frame(
  Model = "KNN",
    Accuracy = overall_stats["Accuracy"],
  
  Kappa = overall_stats["Kappa"],
  
  Sensitivity = class_stats["Sensitivity"],
  Specificity = class_stats["Specificity"],
  
  `Detection Rate` = class_stats["Detection Rate"],
  `Detection Prevalence` = class_stats["Detection Prevalence"],
  `Balanced Accuracy` = class_stats["Balanced Accuracy"],
  AUC= auc(roc_result)
)

# Scrivere i dati nel foglio Excel
writeDataTable(wb, "Statistiche Complete KNN", metrics, withFilter = TRUE)

# Salvare il file Excel
saveWorkbook(wb, "Statistiche_Complete_KNN.xlsx", overwrite = TRUE)

```


Modello Random Forest

```{r random forest}
set.seed(123)
model <- train(
  gruppo ~., data = train.data, method = "rf",
  trControl = trainControl("cv", number = 10),
  importance = TRUE
  )
model$bestTune

```
```{r modello finale}
# Final model
model$finalModel
```
```{r predizione}
# Make predictions on the test data
predicted.classes <- model %>% predict(test.data)
head(predicted.classes)
```
```{r accurancy}
mean(predicted.classes == test.data$gruppo)
```
```{r confusion matrix}
table(test.data$gruppo, predicted.classes)
confusionMatrix(predicted.classes, test.data$gruppo, positive= "1")
```
```{r ROC}
# Calcolo ROC
roc_result <- roc(test.data$gruppo, as.numeric(predicted.classes))

# Stampa l'AUC
print(paste("AUC:", auc(roc_result)))

# Creazione del grafico ROC
plot(roc_result, main="ROC Curve", col="#1c61b6", lwd=2)
abline(a=0, b=1, lty=2, col="red")

```
```{r}


# Creare la matrice di confusione
cm <- confusionMatrix(predicted.classes, test.data$gruppo, positive = "1")

# Estrazione delle metriche dalla matrice di confusione
overall_stats <- cm$overall
cm
# statistiche generali come accuracy e Kappa
class_stats <- cm$byClass  # statistiche per classe come sensibilità, specificità, ecc.

# Creare un nuovo file Excel e un foglio per le statistiche
wb <- createWorkbook()
addWorksheet(wb, "Statistiche Complete RF")

# Preparare i dati da scrivere
metrics <- data.frame(
  Model = "Random Forest",
   Accuracy = overall_stats["Accuracy"],
  
  Kappa = overall_stats["Kappa"],
  
  Sensitivity = class_stats["Sensitivity"],
  Specificity = class_stats["Specificity"],
  
  `Detection Rate` = class_stats["Detection Rate"],
  `Detection Prevalence` = class_stats["Detection Prevalence"],
  `Balanced Accuracy` = class_stats["Balanced Accuracy"],
  AUC= auc(roc_result)
)

# Scrivere i dati nel foglio Excel
writeDataTable(wb, "Statistiche Complete RF", metrics, withFilter = TRUE)

# Salvare il file Excel
saveWorkbook(wb, "Statistiche_Complete_RF.xlsx", overwrite = TRUE)

```


Modello GBM

```{r GBM}
set.seed(123)
model <- train(
  gruppo ~., data = train.data, method = "xgbTree",
  trControl = trainControl("cv", number = 10)
  )

model$bestTune
```
```{r}
table(test.data$gruppo, predicted.classes)
confusionMatrix(predicted.classes, test.data$gruppo, positive= "1")
```
```{r}
varImp(model)
```
```{r ROC}
# Calcolo ROC
roc_result <- roc(test.data$gruppo, as.numeric(predicted.classes))

# Stampa l'AUC
print(paste("AUC:", auc(roc_result)))

# Creazione del grafico ROC
plot(roc_result, main="ROC Curve", col="#1c61b6", lwd=2)
abline(a=0, b=1, lty=2, col="red")

```
```{r}


# Creare la matrice di confusione
cm <- confusionMatrix(predicted.classes, test.data$gruppo, positive = "1")

# Estrazione delle metriche dalla matrice di confusione
overall_stats <- cm$overall
cm
# statistiche generali come accuracy e Kappa
class_stats <- cm$byClass  # statistiche per classe come sensibilità, specificità, ecc.

# Creare un nuovo file Excel e un foglio per le statistiche
wb <- createWorkbook()
addWorksheet(wb, "Statistiche Complete GBM")

# Preparare i dati da scrivere
metrics <- data.frame(
  Model = "GBM",
  Accuracy = overall_stats["Accuracy"],
  
  Kappa = overall_stats["Kappa"],
  
  Sensitivity = class_stats["Sensitivity"],
  Specificity = class_stats["Specificity"],
  
  `Detection Rate` = class_stats["Detection Rate"],
  `Detection Prevalence` = class_stats["Detection Prevalence"],
  `Balanced Accuracy` = class_stats["Balanced Accuracy"],
  AUC= auc(roc_result)
)

# Scrivere i dati nel foglio Excel
writeDataTable(wb, "Statistiche Complete GBM", metrics, withFilter = TRUE)

# Salvare il file Excel
saveWorkbook(wb, "Statistiche_Complete_GBM.xlsx", overwrite = TRUE)

```


Modello Logistic Regression

```{r}

# Funzione per sostituire gli outlier con la mediana
replace_outliers_with_median <- function(x) {
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  q3 <- quantile(x, 0.75, na.rm = TRUE)
  iqr <- q3 - q1
  lower_bound <- q1 - 1.5 * iqr
  upper_bound <- q3 + 1.5 * iqr
  
  # Sostituisce gli outlier con la mediana
  x[x < lower_bound | x > upper_bound] <- median(x, na.rm = TRUE)
  return(x)
}

# Applica la normalizzazione min-max e la sostituzione degli outlier solo alle variabili numeriche
data_clean <- data %>%
  mutate(across(where(is.numeric), ~replace_outliers_with_median(.))) 
# Verifica i dati puliti
print(head(data_clean))
write.xlsx(data_clean, "data_clean.xlsx")
```
```{r data split}
set.seed(42)  # Per riproducibilità
indexes <- createDataPartition(data_clean$gruppo, p=0.7, list=FALSE)
train_data <- data_clean[indexes,]
test_data <- data_clean[-indexes,]
```

```{r}
# Fit the model
fit <- glm(gruppo ~ ., data = train_data, family = binomial())
library(flextable)
# Summarize the model
summary(fit)
coef(fit)
# Definizione dei dati dei coefficienti del modello GLM
coefficients_data <- data.frame(
  Term = c("Intercept", "grado.accondiscendenza1", "tendenza.autosacrificio1",
           "livello.autotrasendenza1", "autotrasendenza", "transpersonal.identification",
           "spirituality", "autosacrificio", "accondiscendenza", "grado.sintomi", "ansia"),
  Estimate = c(-2.6405, 2.2402, -0.9513, 1.3042, -2.4004, 0.5256, 3.1560, -1.4773, 1.6024, 2.0580, 0.4247),
  Std_Error = c(1.8956, 1.6455, 1.7825, 1.3171, 4.9816, 3.5627, 3.5178, 2.7019, 3.0787, 2.4179, 1.8668),
  Z_value = c(-1.393, 1.361, -0.534, 0.990, -0.482, 0.148, 0.897, -0.547, 0.520, 0.851, 0.228),
  Pr_z = c(0.164, 0.173, 0.594, 0.322, 0.630, 0.883, 0.370, 0.585, 0.603, 0.395, 0.820)
)

# Stampa la tabella completa
print(coefficients_data)
t<-flextable(coefficients_data)
t<-autofit(t)
t
save_as_image(t, "RLresult.png", height= 4,  expand = 5, res = 300)
```
```{r}
# Make predictions

predictions <- predict(fit, newdata = test_data, type = "response")
predicted_class <- ifelse(predictions > 0.5, "1", "0")
predicted_class <- factor(predicted_class, levels = levels(test_data$gruppo))
conf_matrix <- table(Predicted = predicted_class, Actual = test_data$gruppo)
```


```{r}
# Model accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
```

```{r AUC}
roc_curve <- roc(test_data$gruppo, predictions)
auc <- auc(roc_curve)

```
```{r}
print(paste("Accuratezza:", accuracy))
print(paste("AUC:", auc))
print("Matrice di confusione:")
print(conf_matrix)
plot(roc_curve)
```



```{r}
table(test_data$gruppo, predicted_class)
confusionMatrix(predicted_class, test_data$gruppo, positive= "1")
```
```{r}


# Creare la matrice di confusione
cm <- confusionMatrix(predicted_class, test_data$gruppo, positive = "1")

# Estrazione delle metriche dalla matrice di confusione
overall_stats <- cm$overall
cm
# statistiche generali come accuracy e Kappa
class_stats <- cm$byClass  # statistiche per classe come sensibilità, specificità, ecc.

# Creare un nuovo file Excel e un foglio per le statistiche
wb <- createWorkbook()
addWorksheet(wb, "Statistiche Complete LR")

# Preparare i dati da scrivere
metrics <- data.frame(
  Model = "Logistic Regression",
  Accuracy = overall_stats["Accuracy"],
  
  Kappa = overall_stats["Kappa"],
  
  Sensitivity = class_stats["Sensitivity"],
  Specificity = class_stats["Specificity"],
  
  `Detection Rate` = class_stats["Detection Rate"],
  `Detection Prevalence` = class_stats["Detection Prevalence"],
  `Balanced Accuracy` = class_stats["Balanced Accuracy"],
  AUC= auc
)

# Scrivere i dati nel foglio Excel
writeDataTable(wb, "Statistiche Complete LR", metrics, withFilter = TRUE)

# Salvare il file Excel
saveWorkbook(wb, "Statistiche_Complete_LR.xlsx", overwrite = TRUE)
sorted<-data.frame(read.xlsx("Statistiche_Complete_LR.xlsx"))
ft<-flextable(sorted)
ft<-autofit(ft)
ft
```


```{r k-fold}
# Define training control
set.seed(123) 
train.control <- trainControl(method = "cv", number = 10)
# Train the model
model2 <- train(gruppo ~ ., data = data_clean, method = "glm", family = binomial(),
                trControl = train.control)
print(model2)
```

Unione delle tabelle dei risultati in un unico file

```{r}
# Percorsi dei file
files <- c("Statistiche_Complete_DT.xlsx",
          "Statistiche_Complete_GBM.xlsx",
          "Statistiche_Complete_KNN.xlsx",
          "Statistiche_Complete_LR.xlsx",
          "Statistiche_Complete_RF.xlsx",
          "Statistiche_Complete_SVM.xlsx")

# Leggere tutti i file e unirli in un unico DataFrame
all_data <- lapply(files, read_excel)
combined_data <- do.call(rbind, all_data)
combined_data$AUC<- as.numeric(combined_data$AUC)
# Ordinare i dati per 'Accuracy' in ordine decrescente
sorted_data <- combined_data %>%
  mutate_if(is.numeric, round, digits = 3) %>% # Arrotonda tutte le colonne num
  select(Model, AUC, Accuracy, Kappa, Sensitivity, Specificity) %>% # Seleziona e ordina le
  arrange(desc(Accuracy)) # Ordina i dati per Accuracy in ordine decrescente
print(sorted_data)
# Salvare il DataFrame trasposto in un nuovo file Excel
write_xlsx(sorted_data, "Statistiche_Complete.xlsx")
ft<-flextable(sorted_data)
ft<-autofit(ft)
ft
save_as_image(ft, "statcompl.png", height= 4,  expand = 5, res = 600)
```




Analisi del dataset prima della regressione

```{r}
library(dplyr)
library(tidyr)
library(broom)
# Select only numeric predictors

model <- glm(gruppo ~., data = data, family = binomial)
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "1", "0")
mydata <- data %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydata)

mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)
```
```{r plot}
ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")
```

```{r}
plot(model, which = 4, id.n = 3)
```
```{r}
# Extract model results
model.data <- augment(model) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```
```{r}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = gruppo), alpha = .5) +
  theme_bw()
```
```{r}
model.data %>% 
  filter(abs(.std.resid) > 3)
```
```{r multicollinearità}
library(car)
car::vif(model)
```
la variabile autotrascendenza dovrebbe essere tolta perchè ha un valore di collinearità >10. dovrebbe anche essere attenzionata la transperosnal identification.
Ricalcolo della regressione logistica con l'eliminazione delle variabili interessate
```{r}
df<-data_clean
df <- df %>%
  select(-c(4,6))
```
```{r data split}
set.seed(42)  # Per riproducibilità
indexes <- createDataPartition(df$gruppo, p=0.7, list=FALSE)
train_data <- df[indexes,]
test_data <- df[-indexes,]
```

```{r}
# Fit the model
fit <- glm(gruppo ~ ., data = train_data, family = binomial())

# Summarize the model
summary(fit)
coef(fit)

```
```{r}
# Make predictions

predictions <- predict(fit, newdata = test_data, type = "response")
predicted_class <- ifelse(predictions > 0.5, "1", "0")
predicted_class <- factor(predicted_class, levels = levels(test_data$gruppo))
conf_matrix <- table(Predicted = predicted_class, Actual = test_data$gruppo)
```


```{r}
# Model accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
```

```{r AUC}
roc_curve <- roc(test_data$gruppo, predictions)
auc <- auc(roc_curve)

```
```{r}
print(paste("Accuratezza:", accuracy))
print(paste("AUC:", auc))
print("Matrice di confusione:")
print(conf_matrix)
plot(roc_curve)
```



```{r}
table(test_data$gruppo, predicted_class)
confusionMatrix(predicted_class, test_data$gruppo, positive= "1")
```

